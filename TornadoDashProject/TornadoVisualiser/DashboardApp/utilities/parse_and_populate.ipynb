{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the information files and populate the database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Apple\": {\n",
      "        \"Device Name\": \"Apple M1\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Read the text file\n",
    "with open('info_files/clinfo.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Define a pattern to extract relevant information\n",
    "pattern = r'(Platform Name|Number of devices|Device Name|Device Vendor|Device Vendor ID|Device Version|Driver Version|Device OpenCL C Version|Device Type|Device Profile|Device Available|Compiler Available|Linker Available|Max compute units|Max clock frequency|Device Partition|Max number of sub-devices|Supported partition types|Supported affinity domains|Max work item dimensions|Max work item sizes|Max work group size|Preferred work group size multiple \\(kernel\\)|Preferred \\/ native vector sizes\\nchar|short|int|long|half|float|double\\nHalf-precision Floating-point support|Single-precision Floating-point support|Denormals|Infinity and NANs|Round to nearest|Round to zero|Round to infinity|IEEE754-2008 fused multiply-add|Support is emulated in software|Correctly-rounded divide and sqrt operations|Double-precision Floating-point support|Address bits|Global memory size|Error Correction support|Max memory allocation|Unified memory for Host and Device|Minimum alignment for any data type|Alignment of base address|Global Memory cache type|Image support|Max number of samplers per kernel|Max size for 1D images from buffer|Max 1D or 2D image array size|Base address alignment for 2D image buffers|Pitch alignment for 2D image buffers|Max 2D image size|Max 3D image size|Max number of read image args|Max number of write image args|Local memory type|Local memory size|Max number of constant args|Max constant buffer size|Max size of kernel argument|Queue properties\\nOut-of-order execution|Profiling|Prefer user sync for interop|Profiling timer resolution|Execution capabilities\\nRun OpenCL kernels|Run native kernels|printf\\(\\) buffer size|Built-in kernels|Device Extensions)\\s+(.*?)\\n'\n",
    "\n",
    "# Find all matches using regular expression\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Create a dictionary to store the extracted information\n",
    "data = {}\n",
    "current_key = ''\n",
    "\n",
    "# Process the matches\n",
    "for match in matches:\n",
    "    if match[0] == 'Platform Name':\n",
    "        platform_name = match[1].strip()\n",
    "        data[platform_name] = {}\n",
    "        current_key = platform_name\n",
    "    else:\n",
    "        key = match[0].strip()\n",
    "        value = match[1].strip()\n",
    "        data[current_key][key] = value\n",
    "\n",
    "# Convert the dictionary to JSON\n",
    "json_data = json.dumps(data, indent=4)\n",
    "\n",
    "# Print or save the JSON data as needed\n",
    "print(json_data)\n",
    "\n",
    "# Optionally, save the JSON data to a file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the existing JSON file\n",
    "with open('output.json', 'r') as json_file:\n",
    "    existing_data = json.load(json_file)\n",
    "\n",
    "# Read the CMake version from the text file\n",
    "with open('info_files/cmake_version.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Define a pattern to extract the CMake version\n",
    "cmake_pattern = r'cmake version (\\d+\\.\\d+\\.\\d+)'\n",
    "\n",
    "# Find the CMake version using regular expression\n",
    "cmake_version_match = re.search(cmake_pattern, text)\n",
    "\n",
    "# Extract the CMake version if found\n",
    "if cmake_version_match:\n",
    "    cmake_version = cmake_version_match.group(1)\n",
    "else:\n",
    "    cmake_version = \"Not Found\"\n",
    "\n",
    "# Add the CMake version to the existing JSON data\n",
    "if \"CMake\" not in existing_data:\n",
    "    existing_data[\"CMake\"] = {}\n",
    "existing_data[\"CMake\"][\"CMake Version\"] = cmake_version\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the existing JSON file\n",
    "with open('output.json', 'r') as json_file:\n",
    "    existing_data = json.load(json_file)\n",
    "\n",
    "# Read the GCC version from the text file\n",
    "with open('info_files/gcc_version.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Define a pattern to extract the GCC version\n",
    "gcc_pattern = r'Apple clang version (\\d+\\.\\d+\\.\\d+)'\n",
    "\n",
    "# Find the GCC version using regular expression\n",
    "gcc_version_match = re.search(gcc_pattern, text)\n",
    "\n",
    "# Extract the GCC version if found\n",
    "if gcc_version_match:\n",
    "    gcc_version = gcc_version_match.group(1)\n",
    "else:\n",
    "    gcc_version = \"Not Found\"\n",
    "\n",
    "# Add the GCC version to the existing JSON data\n",
    "if \"GCC\" not in existing_data:\n",
    "    existing_data[\"GCC\"] = {}\n",
    "existing_data[\"GCC\"][\"GCC Version\"] = gcc_version\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the existing JSON file\n",
    "with open('output.json', 'r') as json_file:\n",
    "    existing_data = json.load(json_file)\n",
    "\n",
    "# Read the Maven version from the text file\n",
    "with open('info_files/maven_version.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Define a pattern to extract the Maven version\n",
    "maven_pattern = r'Apache Maven (\\d+\\.\\d+\\.\\d+)'\n",
    "\n",
    "# Find the Maven version using regular expression\n",
    "maven_version_match = re.search(maven_pattern, text)\n",
    "\n",
    "# Extract the Maven version if found\n",
    "if maven_version_match:\n",
    "    maven_version = maven_version_match.group(1)\n",
    "else:\n",
    "    maven_version = \"Not Found\"\n",
    "\n",
    "# Add the Maven version to the existing JSON data\n",
    "if \"Maven\" not in existing_data:\n",
    "    existing_data[\"Maven\"] = {}\n",
    "existing_data[\"Maven\"][\"Maven Version\"] = maven_version\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Apple\": {\n",
      "        \"Device Name\": \"Apple M1\"\n",
      "    },\n",
      "    \"CMake\": {\n",
      "        \"CMake Version\": \"3.26.4\"\n",
      "    },\n",
      "    \"GCC\": {\n",
      "        \"GCC Version\": \"14.0.0\"\n",
      "    },\n",
      "    \"Maven\": {\n",
      "        \"Maven Version\": \"3.9.3\"\n",
      "    },\n",
      "    \"Platform\": \"Darwin\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Read the existing JSON file\n",
    "with open('output.json', 'r') as json_file:\n",
    "    existing_data = json.load(json_file)\n",
    "\n",
    "# Read the platform information from the text file\n",
    "with open('info_files/platform.txt', 'r') as file:\n",
    "    platform_info = file.read().strip()  # Remove leading/trailing whitespace\n",
    "\n",
    "# Add the platform information to the existing JSON data\n",
    "existing_data[\"Platform\"] = platform_info\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "# Print the updated JSON data\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Python version from the text file\n",
    "with open('info_files/python_version.txt', 'r') as file:\n",
    "    python_version = file.read().strip()  # Remove leading/trailing whitespace\n",
    "\n",
    "# Add the Python version to the existing JSON data\n",
    "existing_data[\"Python\"] = python_version\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saxpy output from the text file\n",
    "with open('info_files/saxpy_output.txt', 'r') as file:\n",
    "    saxpy_data = file.readlines()\n",
    "\n",
    "# Initialize a dictionary to store the extracted data\n",
    "saxpy_info = {}\n",
    "\n",
    "# Loop through each line in the file\n",
    "for line in saxpy_data:\n",
    "    # Split the line based on commas and whitespace\n",
    "    parts = re.split(r'[,\\s]+', line)\n",
    "    \n",
    "    # Extract relevant information\n",
    "    if parts[0].startswith(\"bm=saxpy\"):\n",
    "        benchmark = parts[0].split(\"=\")[1]\n",
    "        device = parts[1].split(\"=\")[1].strip()\n",
    "        average = float(parts[2].split(\"=\")[1])\n",
    "        median = float(parts[3].split(\"=\")[1])\n",
    "        first_iteration = float(parts[4].split(\"=\")[1])\n",
    "        best = float(parts[5].split(\"=\")[1])\n",
    "        \n",
    "        # Store the extracted information in the dictionary\n",
    "        saxpy_info[benchmark] = {\n",
    "            \"Device\": device,\n",
    "            \"Average\": average,\n",
    "            \"Median\": median,\n",
    "            \"FirstIteration\": first_iteration,\n",
    "            \"Best\": best\n",
    "        }\n",
    "\n",
    "# Add the saxpy_info to the existing JSON data (assuming the JSON data is stored in existing_data)\n",
    "existing_data[\"SaxpyOutput\"] = saxpy_info\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sgemm profiler output from the text file\n",
    "with open('info_files/sgemm_profiler_output.txt', 'r') as file:\n",
    "    sgemm_data = file.readlines()\n",
    "\n",
    "# Initialize a dictionary to store the extracted data\n",
    "sgemm_info = {}\n",
    "\n",
    "# Loop through each line in the file\n",
    "for line in sgemm_data:\n",
    "    # Split the line based on commas and whitespace\n",
    "    parts = re.split(r'[,\\s]+', line)\n",
    "    \n",
    "    # Extract relevant information\n",
    "    if parts[0].startswith(\"bm=sgemm\"):\n",
    "        benchmark = parts[0].split(\"=\")[1]\n",
    "        device = parts[1].split(\"=\")[1].strip()\n",
    "        kernel_min = float(parts[2].split(\"=\")[1])\n",
    "        kernel_avg = float(parts[3].split(\"=\")[1])\n",
    "        copy_in_avg = float(parts[4].split(\"=\")[1])\n",
    "        copy_out_avg = float(parts[5].split(\"=\")[1])\n",
    "        \n",
    "        # Store the extracted information in the dictionary\n",
    "        sgemm_info[benchmark] = {\n",
    "            \"Device\": device,\n",
    "            \"KernelMin\": kernel_min,\n",
    "            \"KernelAvg\": kernel_avg,\n",
    "            \"CopyInAvg\": copy_in_avg,\n",
    "            \"CopyOutAvg\": copy_out_avg\n",
    "        }\n",
    "\n",
    "# Add the sgemm_info to the existing JSON data (assuming the JSON data is stored in existing_data)\n",
    "existing_data[\"SgemmProfilerOutput\"] = sgemm_info\n",
    "\n",
    "# Convert the updated dictionary to JSON\n",
    "json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "# Save the updated JSON data back to the file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate graphs from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'django'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdjango\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Avg\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDashboardApp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Run, TotalResults\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'django'"
     ]
    }
   ],
   "source": [
    "from django.db.models import Avg\n",
    "from matplotlib import pyplot as plt\n",
    "from DashboardApp.models import Run, TotalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data from the database for KernelTime\n",
    "average_times_kernel = TotalResults.objects.values('BenchmarkID__RunID').annotate(avg_time=Avg('KernelTime'))\n",
    "\n",
    "# Extract the RunIDs and corresponding average times\n",
    "run_ids_kernel = [item['BenchmarkID__RunID'] for item in average_times_kernel]\n",
    "average_time_values_kernel = [item['avg_time'] for item in average_times_kernel]\n",
    "\n",
    "# Create a Matplotlib figure and plot the data for KernelTime\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(run_ids_kernel, average_time_values_kernel, marker='o', linestyle='-', color='b')\n",
    "plt.title('RunID vs KernelTime')\n",
    "plt.xlabel('RunID')\n",
    "plt.ylabel('KernelTime')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the graph as a vector image (SVG)\n",
    "plt.savefig('runid_vs_kerneltime.svg', format='svg')\n",
    "\n",
    "# Show the graph (optional)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data from the database for CodeGenerationTime\n",
    "average_times_code_generation = TotalResults.objects.values('BenchmarkID__RunID').annotate(avg_time=Avg('CodeGenerationTime'))\n",
    "\n",
    "# Extract the RunIDs and corresponding average times\n",
    "run_ids_code_generation = [item['BenchmarkID__RunID'] for item in average_times_code_generation]\n",
    "average_time_values_code_generation = [item['avg_time'] for item in average_times_code_generation]\n",
    "\n",
    "# Create a Matplotlib figure and plot the data for CodeGenerationTime\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(run_ids_code_generation, average_time_values_code_generation, marker='o', linestyle='-', color='b')\n",
    "plt.title('RunID vs CodeGenerationTime')\n",
    "plt.xlabel('RunID')\n",
    "plt.ylabel('CodeGenerationTime')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the graph as a vector image (SVG)\n",
    "plt.savefig('runid_vs_codegenerationtime.svg', format='svg')\n",
    "\n",
    "# Show the graph (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data from the database for DriverCompilationTime\n",
    "average_times_driver_compilation = TotalResults.objects.values('BenchmarkID__RunID').annotate(avg_time=Avg('DriverCompilationTime'))\n",
    "\n",
    "# Extract the RunIDs and corresponding average times\n",
    "run_ids_driver_compilation = [item['BenchmarkID__RunID'] for item in average_times_driver_compilation]\n",
    "average_time_values_driver_compilation = [item['avg_time'] for item in average_times_driver_compilation]\n",
    "\n",
    "# Create a Matplotlib figure and plot the data for DriverCompilationTime\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(run_ids_driver_compilation, average_time_values_driver_compilation, marker='o', linestyle='-', color='b')\n",
    "plt.title('RunID vs DriverCompilationTime')\n",
    "plt.xlabel('RunID')\n",
    "plt.ylabel('DriverCompilationTime')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the graph as a vector image (SVG)\n",
    "plt.savefig('runid_vs_drivercompilationtime.svg', format='svg')\n",
    "\n",
    "# Show the graph (optional)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
